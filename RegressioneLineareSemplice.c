#include <stdio.h>

void simple_linear_regression(int n, double x[], double y[], double* slope, double* intercept) {
    double sum_x = 0, sum_y = 0, sum_xy = 0, sum_x2 = 0;
    for(int i = 0; i < n; i++) {
        sum_x += x[i];
        sum_y += y[i];
        sum_xy += x[i] * y[i];
        sum_x2 += x[i] * x[i];
    }
    double x_mean = sum_x / n;
    double y_mean = sum_y / n;

    *slope = (sum_xy - n * x_mean * y_mean) / (sum_x2 - n * x_mean * x_mean);
    *intercept = y_mean - (*slope) * x_mean;
}

int main() {
    double x[] = {1, 2, 3, 4, 5};
    double y[] = {2, 4, 6, 8, 10}; // Perfettamente allineati, senza rumore
    int n = sizeof(x) / sizeof(x[0]);
    double slope, intercept;

    simple_linear_regression(n, x, y, &slope, &intercept);
    printf("Slope: %f, Intercept: %f\n", slope, intercept);

    return 0;
}



/*Nel secondo esempio pratico, il codice in C Ã¨ progettato per implementare la regressione lineare semplice usando il metodo dei minimi quadrati. Vediamo in dettaglio la teoria dietro l'algoritmo e perchÃ© sono state fatte certe scelte nel codice.

Teoria
1. Regressione Lineare Semplice:
La regressione lineare Ã¨ uno dei metodi piÃ¹ basilari ed efficaci per modellare una relazione tra una variabile dipendente 
ð‘¦
y e una variabile indipendente 
ð‘¥
x. L'obiettivo Ã¨ trovare una linea retta,
ð‘¦
=
ð‘š
ð‘¥
+
ð‘
y=mx+b
che meglio approssima i dati nel senso dei minimi quadrati. In questa equazione, 
ð‘š
m rappresenta la pendenza della linea, e 
ð‘
b Ã¨ l'intercetta con l'asse 
ð‘¦
y.

2. Metodo dei Minimi Quadrati:
Il metodo dei minimi quadrati Ã¨ un approccio standard per la regressione lineare. Si cerca di minimizzare la somma dei quadrati delle differenze tra i valori osservati e quelli previsti dalla linea retta. Le formule per calcolare 
ð‘š
m (pendenza) e 
ð‘
b (intercetta) da un set di dati sono:
ð‘š
=
âˆ‘
(
ð‘¥
ð‘–
âˆ’
ð‘¥
Ë‰
)
(
ð‘¦
ð‘–
âˆ’
ð‘¦
Ë‰
)
âˆ‘
(
ð‘¥
ð‘–
âˆ’
ð‘¥
Ë‰
)
2
m= 
âˆ‘(x 
i
â€‹
 âˆ’ 
x
Ë‰
 ) 
2
 
âˆ‘(x 
i
â€‹
 âˆ’ 
x
Ë‰
 )(y 
i
â€‹
 âˆ’ 
y
Ë‰
â€‹
 )
â€‹
 
ð‘
=
ð‘¦
Ë‰
âˆ’
ð‘š
ð‘¥
Ë‰
b= 
y
Ë‰
â€‹
 âˆ’m 
x
Ë‰
 
dove 
ð‘¥
Ë‰
x
Ë‰
  e 
ð‘¦
Ë‰
y
Ë‰
â€‹
  sono le medie delle variabili 
ð‘¥
x e 
ð‘¦
y rispettivamente.

Componenti del Codice
1. Funzione per la Regressione Lineare:

c
Copia codice
void simple_linear_regression(int n, double x[], double y[], double* slope, double* intercept) {
    double sum_x = 0, sum_y = 0, sum_xy = 0, sum_x2 = 0;
    for(int i = 0; i < n; i++) {
        sum_x += x[i];
        sum_y += y[i];
        sum_xy += x[i] * y[i];
        sum_x2 += x[i] * x[i];
    }
    double x_mean = sum_x / n;
    double y_mean = sum_y / n;

    *slope = (sum_xy - n * x_mean * y_mean) / (sum_x2 - n * x_mean * x_mean);
    *intercept = y_mean - (*slope) * x_mean;
}
Questa funzione calcola la pendenza 
ð‘š
m e l'intercetta 
ð‘
b per un dataset utilizzando le formule dei minimi quadrati. Si utilizzano cicli e operazioni matematiche di base senza l'uso di librerie esterne, il che rende l'esempio utile per comprendere i principi fondamentali senza dipendenze.

2. Applicazione della Funzione:

c
Copia codice
int main() {
    double x[] = {1, 2, 3, 4, 5};
    double y[] = {2, 4, 6, 8, 10}; // Perfettamente allineati, senza rumore
    int n = sizeof(x) / sizeof(x[0]);
    double slope, intercept;

    simple_linear_regression(n, x, y, &slope, &intercept);
    printf("Slope: %f, Intercept: %f\n", slope, intercept);

    return 0;
}
Nel main, si definisce un semplice set di dati senza rumore per cui la relazione lineare Ã¨ perfetta. La funzione simple_linear_regression Ã¨ chiamata per calcolare e poi stampare la pendenza e l'intercetta.

UtilitÃ 
Questo esempio Ã¨ utile per apprendere come implementare algoritmi di base senza l'ausilio di librerie complesse, fornendo una comprensione profonda del processo di calcolo nell'ambito della regressione lineare. Ãˆ particolarmente indicato per chi inizia a esplorare il campo della data science e del machine learning per comprendere i meccanismi di base dell'apprendimento supervisionato.*/